{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import selenium \n",
    "from selenium import webdriver\n",
    "import pandas as pd\n",
    "import time\n",
    "from selenium.common.exceptions import StaleElementReferenceException, NoSuchElementException\n",
    "import requests\n",
    "import os\n",
    "import urllib.request\n",
    "from bs4 import BeautifulSoup as bs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Write a python program which searches all the product under a particular product from\n",
    "www.amazon.in. The product to be searched will be taken as input from user. For e.g. If user\n",
    "input is ‘guitar’. Then search for guitars.\n",
    "2. In the above question, now scrape the following details of each product listed in first 3 pages\n",
    "of your search results and save it in a dataframe and csv. In case if any product has less than 3\n",
    "pages in search results then scrape all the products available under that product vertical.\n",
    "Details to be scraped are: \"Brand Name\", \"Name of the Product\", \"Rating\", \"No. of Ratings\",\n",
    "\"Price\", \"Return/Exchange\", \"Expected Delivery\", \"Availability\", \"Other Details\" and\n",
    "“Product URL”. In case, if any of the details are missing for any of the product then replace it\n",
    "by “-“."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#importing driver\n",
    "driver=webdriver.Chrome(r'C:\\Users\\Alby\\Desktop\\chromedriver\\chromedriver.exe')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 457,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "url='https://www.amazon.in/'\n",
    "driver.get(url)\n",
    "\n",
    "#search bar\n",
    "search_bar=driver.find_element_by_id('twotabsearchtextbox')\n",
    "search_bar.send_keys('headphones')\n",
    "\n",
    "#search button\n",
    "search_button=driver.find_element_by_id('nav-search-submit-button')\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#product name\n",
    "Product_names=[]\n",
    "total_rating=[]\n",
    "Price=[]\n",
    "Del_date=[]\n",
    "Prod_url=[]\n",
    "\n",
    "for i in range(2):\n",
    "    #product names\n",
    "    product_tags=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base a-text-normal']\")\n",
    "    time.sleep(3)\n",
    "    for names in product_tags:\n",
    "        if names.text is None:\n",
    "            Product_names.append(\"-\")\n",
    "        else:\n",
    "            Product_names.append(names.text)\n",
    "    \n",
    "    #rating\n",
    "    tot_rating=driver.find_elements_by_xpath(\"//span[@class='a-size-base']\")\n",
    "    for i in tot_rating:\n",
    "         if i.text is None:\n",
    "            total_rating.append(\"-\")\n",
    "         else:\n",
    "            total_rating.append(i.text)\n",
    "        \n",
    "    #total price\n",
    "    tot_price=driver.find_elements_by_xpath(\"//span[@class='a-price-whole']\")\n",
    "    for price in tot_price:\n",
    "        if price.text is None:\n",
    "            Price.append(\"-\")\n",
    "        else:\n",
    "            Price.append(price.text)\n",
    "    \n",
    "    #expected delivery\n",
    "    ex_del=driver.find_elements_by_xpath(\"//span[@class='a-text-bold']\")\n",
    "    \n",
    "    for day in ex_del:\n",
    "        if day.text is None:\n",
    "            Del_date.append(\"-\")\n",
    "        else:\n",
    "            Del_date.append(day.text)\n",
    "        \n",
    "    prod_url=driver.find_elements_by_xpath(\"//a[@class='a-link-normal a-text-normal']\")\n",
    "    for i in prod_url:\n",
    "        Prod_url.append(i.get_attribute('href'))\n",
    "\n",
    "    \n",
    "    #next button\n",
    "    time.sleep(5)\n",
    "    next=driver.find_element_by_xpath(\"//li[@class='a-last']//a\")#scraping the list of buttons from the page\n",
    "    next_button=driver.get(next.get_attribute('href'))\n",
    "#getting brand names\n",
    "Brand=[]\n",
    "for names in Product_names:\n",
    "    Brand.append(names.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 458,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for details inside each urls\n",
    "\n",
    "Availability=[]\n",
    "Rating=[]\n",
    "other_feature=[]\n",
    "\n",
    "#accessing each urls\n",
    "for item in Prod_url:\n",
    "    time.sleep(1)\n",
    "    driver.get(item)\n",
    "   \n",
    "#accessing availbilty\n",
    "    avail=driver.find_elements_by_id(\"availability\")\n",
    "    for status in avail:\n",
    "        Availability.append(status.text.replace('\\n',\" \"))\n",
    "    \n",
    "    #accessing raing\n",
    "    rating=driver.find_elements_by_xpath(\"//span[@class='a-size-medium a-color-base']\")\n",
    "    for j in rating:\n",
    "        if j.text is None:\n",
    "            Rating.append(\"-\")\n",
    "        else:\n",
    "            Rating.append(j.text)\n",
    "\n",
    "#others\n",
    "    other_features=driver.find_elements_by_xpath(\"//td[@class='a-span9']//span\")\n",
    "    for feat in other_features:\n",
    "        if feat.text is None:\n",
    "            other_feature.append(\"-\")\n",
    "        else:\n",
    "            other_feature.append(feat.text)\n",
    "    other_feature.append(\"+\") #adding + sign so that it is easier to split later\n",
    "\n",
    "    #partitioning the features list\n",
    "others = []\n",
    "temp = []\n",
    "for item in other_feature:\n",
    "    temp.append(item)\n",
    "    if item == '+':\n",
    "        others.append(temp)\n",
    "        temp = []\n",
    "if temp:\n",
    "    others.append(temp)\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Product_name</th>\n",
       "      <th>Brand</th>\n",
       "      <th>price</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Availability</th>\n",
       "      <th>Delivery_by</th>\n",
       "      <th>Numberof_ratings</th>\n",
       "      <th>Other_details</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Marshall Major III Bluetooth Wireless On-Ear H...</td>\n",
       "      <td>Marshall</td>\n",
       "      <td>7,499</td>\n",
       "      <td>4.4 out of 5</td>\n",
       "      <td>Only 1 left in stock.</td>\n",
       "      <td>Thursday, July 8</td>\n",
       "      <td>8,070</td>\n",
       "      <td>[Marshall, Black, Bluetooth, Major 3 BT, On Ea...</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fire-Boltt Blast 1400 Over -Ear Bluetooth Wire...</td>\n",
       "      <td>Fire-Boltt</td>\n",
       "      <td>2,499</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Thursday, July 8</td>\n",
       "      <td>4,900</td>\n",
       "      <td>[Fire-Boltt, Black, Wireless, BH1400, Over Ear...</td>\n",
       "      <td>https://www.amazon.in/gp/slredirect/picassoRed...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>boAt Bassheads 900 On Ear Wired Headphones(Car...</td>\n",
       "      <td>boAt</td>\n",
       "      <td>799</td>\n",
       "      <td>4.2 out of 5</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Thursday, July 8</td>\n",
       "      <td>43,278</td>\n",
       "      <td>[BoAt, Carbon Black, Wired, BassHeads, On Ear, +]</td>\n",
       "      <td>https://www.amazon.in/Boat-BassHeads-900-Wired...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>boAt Rockerz 450 On-Ear Headphones with 15 Hou...</td>\n",
       "      <td>boAt</td>\n",
       "      <td>1,199</td>\n",
       "      <td>4.1 out of 5</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Monday, July 12</td>\n",
       "      <td>33,894</td>\n",
       "      <td>[BoAt, Luscious Black, Wireless, Rockerz 450, ...</td>\n",
       "      <td>https://www.amazon.in/Rockerz-450-Wireless-Blu...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Zebronics Zeb-Thunder Wireless BT Headphone Co...</td>\n",
       "      <td>Zebronics</td>\n",
       "      <td>699</td>\n",
       "      <td>3.9 out of 5</td>\n",
       "      <td>In stock.</td>\n",
       "      <td>Friday, July 9</td>\n",
       "      <td>21,812</td>\n",
       "      <td>[ZEBRONICS, Blue, Bluetooth, Wired, ZEB-Thunde...</td>\n",
       "      <td>https://www.amazon.in/Zebronics-Zeb-Thunder-Bl...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Product_name       Brand  price  \\\n",
       "0  Marshall Major III Bluetooth Wireless On-Ear H...    Marshall  7,499   \n",
       "1  Fire-Boltt Blast 1400 Over -Ear Bluetooth Wire...  Fire-Boltt  2,499   \n",
       "2  boAt Bassheads 900 On Ear Wired Headphones(Car...        boAt    799   \n",
       "3  boAt Rockerz 450 On-Ear Headphones with 15 Hou...        boAt  1,199   \n",
       "4  Zebronics Zeb-Thunder Wireless BT Headphone Co...   Zebronics    699   \n",
       "\n",
       "         Rating           Availability       Delivery_by Numberof_ratings  \\\n",
       "0  4.4 out of 5  Only 1 left in stock.  Thursday, July 8            8,070   \n",
       "1  4.1 out of 5              In stock.  Thursday, July 8            4,900   \n",
       "2  4.2 out of 5              In stock.  Thursday, July 8           43,278   \n",
       "3  4.1 out of 5              In stock.   Monday, July 12           33,894   \n",
       "4  3.9 out of 5              In stock.    Friday, July 9           21,812   \n",
       "\n",
       "                                       Other_details  \\\n",
       "0  [Marshall, Black, Bluetooth, Major 3 BT, On Ea...   \n",
       "1  [Fire-Boltt, Black, Wireless, BH1400, Over Ear...   \n",
       "2  [BoAt, Carbon Black, Wired, BassHeads, On Ear, +]   \n",
       "3  [BoAt, Luscious Black, Wireless, Rockerz 450, ...   \n",
       "4  [ZEBRONICS, Blue, Bluetooth, Wired, ZEB-Thunde...   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "1  https://www.amazon.in/gp/slredirect/picassoRed...  \n",
       "2  https://www.amazon.in/Boat-BassHeads-900-Wired...  \n",
       "3  https://www.amazon.in/Rockerz-450-Wireless-Blu...  \n",
       "4  https://www.amazon.in/Zebronics-Zeb-Thunder-Bl...  "
      ]
     },
     "execution_count": 460,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Amazon_headphones=pd.DataFrame({})\n",
    "Amazon_headphones[\"Product_name\"]=Product_names[0:45]\n",
    "Amazon_headphones[\"Brand\"]=Brand[0:45]\n",
    "Amazon_headphones[\"price\"]=Price[0:45]\n",
    "Amazon_headphones[\"Rating\"]=Rating[0:45]\n",
    "Amazon_headphones[\"Availability\"]=Availability[0:45]\n",
    "Amazon_headphones[\"Delivery_by\"]=Del_date[0:45]\n",
    "Amazon_headphones[\"Numberof_ratings\"]=total_rating[0:45]\n",
    "Amazon_headphones[\"Other_details\"]=others[0:45]\n",
    "Amazon_headphones[\"url\"]=Prod_url[0:45]\n",
    "Amazon_headphones.to_csv('Amazon_headphones.csv')\n",
    "Amazon_headphones.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Write a python program to access the search bar and search button on images.google.com and scrape 100 images each for keywords ‘fruits’, ‘cars’ and ‘Machine Learning’."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "url='https://images.google.com/'\n",
    "driver.get(url)\n",
    "time.sleep(7)\n",
    "\n",
    "#search bar\n",
    "search_bar=driver.find_element_by_xpath('/html/body/div[2]/div[2]/div/form/div[1]/div[1]/div[1]/div/div[2]/input')\n",
    "search_bar.send_keys('fruits')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#search_button\n",
    "search_button=driver.find_element_by_xpath(\"//span[@class='z1asCe MZy1Rb']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scolling\n",
    "for i in range(1,10):\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollBy(0, 4000)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fruits images\n",
    "count=0\n",
    "kk=(r'C:\\Users\\Alby\\Desktop\\projects\\fliprobo\\Selenium\\Images\\Fruits')\n",
    "elements = driver.find_elements_by_xpath('//img[contains(@class,\"rg_i Q4LuWd\")]')\n",
    "for i in elements[:100]:\n",
    "    src = i.get_attribute('src')\n",
    "    try:\n",
    "        if src != None:\n",
    "            src  = str(src)\n",
    "            count+=1\n",
    "            \n",
    "            urllib.request.urlretrieve(src, os.path.join(kk,'fruits'+str(count)+'.jpg'))\n",
    "        else:\n",
    "            raise TypeError\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping cars images\n",
    "url='https://images.google.com/'\n",
    "driver.get(url)\n",
    "time.sleep(7)\n",
    "\n",
    "#search bar\n",
    "search_bar=driver.find_element_by_xpath('/html/body/div[2]/div[2]/div/form/div[1]/div[1]/div[1]/div/div[2]/input')\n",
    "search_bar.send_keys('Cars')\n",
    "time.sleep(2)\n",
    "#search_button\n",
    "search_button=driver.find_element_by_xpath(\"//span[@class='z1asCe MZy1Rb']\")\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "#scolling\n",
    "for i in range(1,10):\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollBy(0, 4000)\") \n",
    "    \n",
    "#cars images\n",
    "count=0\n",
    "car=(r'C:\\Users\\Alby\\Desktop\\projects\\fliprobo\\Selenium\\Images\\Cars')\n",
    "elements = driver.find_elements_by_xpath('//img[contains(@class,\"rg_i Q4LuWd\")]')\n",
    "for i in elements[:100]:\n",
    "    src = i.get_attribute('src')\n",
    "    try:\n",
    "        if src != None:\n",
    "            src  = str(src)\n",
    "            count+=1\n",
    "            \n",
    "            urllib.request.urlretrieve(src, os.path.join(car,'cars'+str(count)+'.jpg'))\n",
    "        else:\n",
    "            raise TypeError\n",
    "    except TypeError:\n",
    "        pass\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "#scrapping machine learning images\n",
    "url='https://images.google.com/'\n",
    "driver.get(url)\n",
    "time.sleep(7)\n",
    "\n",
    "#search bar\n",
    "search_bar=driver.find_element_by_xpath('/html/body/div[2]/div[2]/div/form/div[1]/div[1]/div[1]/div/div[2]/input')\n",
    "search_bar.send_keys('Machine learning')\n",
    "time.sleep(2)\n",
    "#search_button\n",
    "search_button=driver.find_element_by_xpath(\"//span[@class='z1asCe MZy1Rb']\")\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#scolling\n",
    "for i in range(1,10):\n",
    "    time.sleep(2)\n",
    "    driver.execute_script(\"window.scrollBy(0, 4000)\") \n",
    "    \n",
    "#machine learning images\n",
    "count=0\n",
    "Machine_learning=(r'C:\\Users\\Alby\\Desktop\\projects\\fliprobo\\Selenium\\Images\\Machine learning')\n",
    "elements = driver.find_elements_by_xpath('//img[contains(@class,\"rg_i Q4LuWd\")]')\n",
    "for i in elements[:100]:\n",
    "    src = i.get_attribute('src')\n",
    "    try:\n",
    "        if src != None:\n",
    "            src  = str(src)\n",
    "            count+=1\n",
    "            \n",
    "            urllib.request.urlretrieve(src, os.path.join(Machine_learning,'ML'+str(count)+'.jpg'))\n",
    "        else:\n",
    "            raise TypeError\n",
    "    except TypeError:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Write a python program to search for a smartphone(e.g.: Oneplus Nord, pixel 4A, etc.) on www.flipkart.com and scrape following details for all the search results displayed on 1st page. Details to be scraped: “Brand Name”, “Smartphone name”, “Colour”, “RAM”, “Storage(ROM)”, “Primary Camera”, “Secondary Camera”, “Display Size”, “Display Resolution”, “Processor”, “Processor Cores”, “Battery Capacity”, “Price”, “Product URL”. In case if any of the details is missing then replace it by “- “. Save your results in a dataframe and CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "url='https://www.flipkart.com/'\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#close login prompt\n",
    "try:\n",
    "    btn=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _2doB4z']\")\n",
    "    btn.click()\n",
    "except NoSuchElementException:\n",
    "    pass\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#sarch bar\n",
    "search_bar=driver.find_element_by_xpath(\"/html/body/div[1]/div/div[1]/div[1]/div[2]/div[2]/form/div/div/input\")\n",
    "\n",
    "\n",
    "#passing key word\n",
    "search_bar.send_keys(\"pixel 4a\")\n",
    "\n",
    "#search_button\n",
    "search_button=driver.find_element_by_xpath(\"//button[@class='L0Z3Pu']\")\n",
    "search_button.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lists to be scraped\n",
    "phone_name=[]\n",
    "Prod_urls=[]\n",
    "Price=[]\n",
    "name_tags=driver.find_elements_by_xpath(\"//div[@class='_4rR01T']\")\n",
    "for name in name_tags:\n",
    "    phone_name.append(name.text)\n",
    "price_tags=driver.find_elements_by_xpath(\"//div[@class='_30jeq3 _1_WHN1']\")\n",
    "for price in price_tags:\n",
    "    Price.append(price.text)\n",
    "\n",
    "#taking in urls   \n",
    "urls=driver.find_elements_by_xpath(\"//a[@class='_1fQZEK']\")\n",
    "for i in urls:\n",
    "    Prod_urls.append(i.get_attribute('href'))\n",
    "\n",
    "\n",
    "#extracting brand names\n",
    "Brand=[]\n",
    "for i in phone_name:\n",
    "    Brand.append(i.split()[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "#accessing details inside each products\n",
    "Ram=[]\n",
    "Colour=[]\n",
    "ROM=[]\n",
    "Prim_Cam=[]\n",
    "Display=[]\n",
    "Resolution=[]\n",
    "Battery=[]\n",
    "Rows=[]\n",
    "value=[]\n",
    "for url in Prod_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(4)\n",
    "    \n",
    "    #clicking read more button\n",
    "    read_more=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _1FH0tX']\")\n",
    "    read_more.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #saving table\n",
    "    table_rows=driver.find_elements_by_xpath(\"//tr[@class='_1s_Smc row']\")\n",
    "    for i in table_rows:\n",
    "        Rows.append(i.text)\n",
    "        \n",
    "    for name in table_rows:\n",
    "        tex=name.find_element_by_xpath(\"td[1]\").text \n",
    "\n",
    "        #Color\n",
    "        if tex=='Color':\n",
    "            \n",
    "            Colour.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "        #Extracting Display Size\n",
    "        if tex=='Display Size':\n",
    "            Display.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "\n",
    "        #Resolution\n",
    "        if tex=='Resolution':\n",
    "             Resolution.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "\n",
    "        #Processor        \n",
    "        if tex=='Processor Type':\n",
    "            Processor.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "\n",
    "        #Cores\n",
    "        if tex=='Processor Core':\n",
    "            Cores.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "\n",
    "        #ROM\n",
    "        if tex=='Internal Storage':\n",
    "            ROM.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "\n",
    "        #RAM Memory\n",
    "        if tex=='RAM':\n",
    "            Ram.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "\n",
    "        #Extracting Primary Camera Details\n",
    "        if tex=='Primary Camera':\n",
    "            Prim_Cam.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "        # Extracting Battery Capacity\n",
    "        if tex=='Battery Capacity':\n",
    "            Battery.append(name.find_element_by_xpath(\"td[2]\").text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 360,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rows=[]\n",
    "Sec_cam=[]\n",
    "Processor=[]\n",
    "Cores=[]\n",
    "\n",
    "for url in Prod_urls:\n",
    "    soup1=[]\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    page_source = driver.page_source\n",
    "    soup = bs(page_source, 'lxml')\n",
    "    soup=soup.find_all('td',class_='_1hKmbr col col-3-12')\n",
    "    for i in soup:\n",
    "        soup1.append(i.text)\n",
    "    \n",
    "    #clicking read more button\n",
    "    read_more=driver.find_element_by_xpath(\"//button[@class='_2KpZ6l _1FH0tX']\")\n",
    "    read_more.click()\n",
    "    time.sleep(3)\n",
    "    \n",
    "    #saving table\n",
    "    table_rows=driver.find_elements_by_xpath(\"//tr[@class='_1s_Smc row']\")\n",
    "    if 'Secondary Camera' in soup1:\n",
    "        for name in table_rows:\n",
    "            tes=name.find_element_by_xpath(\"td[1]\").text\n",
    "            if tes=='Secondary Camera':\n",
    "                Sec_cam.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "    else:\n",
    "        Sec_cam.append(\"-\")\n",
    "        \n",
    "    if 'Processor Type' in soup1:\n",
    "        for name in table_rows:\n",
    "            tes=name.find_element_by_xpath(\"td[1]\").text\n",
    "            if tes=='Processor Type':\n",
    "                Processor.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "    else:\n",
    "        Processor.append(\"-\")\n",
    "        \n",
    "    if 'Processor Core' in soup1:\n",
    "        for name in table_rows:\n",
    "            tes=name.find_element_by_xpath(\"td[1]\").text\n",
    "            if tes=='Processor Core':\n",
    "                Cores.append(name.find_element_by_xpath(\"td[2]\").text)\n",
    "    else:\n",
    "        Cores.append(\"-\")           "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Phone_name</th>\n",
       "      <th>Price</th>\n",
       "      <th>Brand</th>\n",
       "      <th>Colour</th>\n",
       "      <th>Ram</th>\n",
       "      <th>ROM</th>\n",
       "      <th>Prim_Cam</th>\n",
       "      <th>Sec_cam</th>\n",
       "      <th>Display</th>\n",
       "      <th>Resolution</th>\n",
       "      <th>Processor</th>\n",
       "      <th>Cores</th>\n",
       "      <th>Battery</th>\n",
       "      <th>Prod_urls</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Google Pixel 4a (Just Black, 128 GB)</td>\n",
       "      <td>₹31,999</td>\n",
       "      <td>Google</td>\n",
       "      <td>Just Black</td>\n",
       "      <td>6 GB</td>\n",
       "      <td>128 GB</td>\n",
       "      <td>12.2MP Rear Camera</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>14.76 cm (5.81 inch)</td>\n",
       "      <td>2340 x 1080 Pixels</td>\n",
       "      <td>Qualcomm Snapdragon 730G</td>\n",
       "      <td>Octa Core</td>\n",
       "      <td>3140 mAh</td>\n",
       "      <td>https://www.flipkart.com/google-pixel-4a-just-...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>REDMI Note 9 (Shadow Black, 64 GB)</td>\n",
       "      <td>₹10,999</td>\n",
       "      <td>REDMI</td>\n",
       "      <td>Shadow Black</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>64 GB</td>\n",
       "      <td>48MP + 8MP + 2MP + 2MP</td>\n",
       "      <td>13MP Front Camera</td>\n",
       "      <td>16.59 cm (6.53 inch)</td>\n",
       "      <td>2340 x 1080 Pixels</td>\n",
       "      <td>MediaTek Helio G85</td>\n",
       "      <td>Octa Core</td>\n",
       "      <td>5020 mAh</td>\n",
       "      <td>https://www.flipkart.com/redmi-note-9-shadow-b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>REDMI 9 Prime (Mint Green, 64 GB)</td>\n",
       "      <td>₹9,999</td>\n",
       "      <td>REDMI</td>\n",
       "      <td>Mint Green</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>64 GB</td>\n",
       "      <td>13MP Rear Camera</td>\n",
       "      <td>8MP Front Camera</td>\n",
       "      <td>16.59 cm (6.53 inch)</td>\n",
       "      <td>2340 x 1080 Pixels</td>\n",
       "      <td>MediaTek Helio G80</td>\n",
       "      <td>Octa Core</td>\n",
       "      <td>5020 mAh</td>\n",
       "      <td>https://www.flipkart.com/redmi-9-prime-mint-gr...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>REDMI Note 9 (Pebble Grey, 64 GB)</td>\n",
       "      <td>₹10,999</td>\n",
       "      <td>REDMI</td>\n",
       "      <td>Pebble Grey</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>64 GB</td>\n",
       "      <td>48MP + 8MP + 2MP + 2MP</td>\n",
       "      <td>13MP Front Camera</td>\n",
       "      <td>16.59 cm (6.53 inch)</td>\n",
       "      <td>2340 x 1080 Pixels</td>\n",
       "      <td>MediaTek Helio G85</td>\n",
       "      <td>Octa Core</td>\n",
       "      <td>5020 mAh</td>\n",
       "      <td>https://www.flipkart.com/redmi-note-9-pebble-g...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>REDMI Note 9 (Arctic White, 64 GB)</td>\n",
       "      <td>₹10,999</td>\n",
       "      <td>REDMI</td>\n",
       "      <td>Arctic White</td>\n",
       "      <td>4 GB</td>\n",
       "      <td>64 GB</td>\n",
       "      <td>48MP + 8MP + 2MP + 2MP</td>\n",
       "      <td>13MP Front Camera</td>\n",
       "      <td>16.59 cm (6.53 inch)</td>\n",
       "      <td>2340 x 1080 Pixels</td>\n",
       "      <td>MediaTek Helio G85</td>\n",
       "      <td>Octa Core</td>\n",
       "      <td>5020 mAh</td>\n",
       "      <td>https://www.flipkart.com/redmi-note-9-arctic-w...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Phone_name    Price   Brand        Colour   Ram  \\\n",
       "0  Google Pixel 4a (Just Black, 128 GB)  ₹31,999  Google    Just Black  6 GB   \n",
       "1    REDMI Note 9 (Shadow Black, 64 GB)  ₹10,999   REDMI  Shadow Black  4 GB   \n",
       "2     REDMI 9 Prime (Mint Green, 64 GB)   ₹9,999   REDMI    Mint Green  4 GB   \n",
       "3     REDMI Note 9 (Pebble Grey, 64 GB)  ₹10,999   REDMI   Pebble Grey  4 GB   \n",
       "4    REDMI Note 9 (Arctic White, 64 GB)  ₹10,999   REDMI  Arctic White  4 GB   \n",
       "\n",
       "      ROM                Prim_Cam            Sec_cam               Display  \\\n",
       "0  128 GB      12.2MP Rear Camera   8MP Front Camera  14.76 cm (5.81 inch)   \n",
       "1   64 GB  48MP + 8MP + 2MP + 2MP  13MP Front Camera  16.59 cm (6.53 inch)   \n",
       "2   64 GB        13MP Rear Camera   8MP Front Camera  16.59 cm (6.53 inch)   \n",
       "3   64 GB  48MP + 8MP + 2MP + 2MP  13MP Front Camera  16.59 cm (6.53 inch)   \n",
       "4   64 GB  48MP + 8MP + 2MP + 2MP  13MP Front Camera  16.59 cm (6.53 inch)   \n",
       "\n",
       "           Resolution                 Processor      Cores   Battery  \\\n",
       "0  2340 x 1080 Pixels  Qualcomm Snapdragon 730G  Octa Core  3140 mAh   \n",
       "1  2340 x 1080 Pixels        MediaTek Helio G85  Octa Core  5020 mAh   \n",
       "2  2340 x 1080 Pixels        MediaTek Helio G80  Octa Core  5020 mAh   \n",
       "3  2340 x 1080 Pixels        MediaTek Helio G85  Octa Core  5020 mAh   \n",
       "4  2340 x 1080 Pixels        MediaTek Helio G85  Octa Core  5020 mAh   \n",
       "\n",
       "                                           Prod_urls  \n",
       "0  https://www.flipkart.com/google-pixel-4a-just-...  \n",
       "1  https://www.flipkart.com/redmi-note-9-shadow-b...  \n",
       "2  https://www.flipkart.com/redmi-9-prime-mint-gr...  \n",
       "3  https://www.flipkart.com/redmi-note-9-pebble-g...  \n",
       "4  https://www.flipkart.com/redmi-note-9-arctic-w...  "
      ]
     },
     "execution_count": 362,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "flipkart=pd.DataFrame({})\n",
    "flipkart['Phone_name']=phone_name\n",
    "flipkart['Price']=Price\n",
    "flipkart['Brand']=Brand\n",
    "flipkart['Colour']=Colour\n",
    "flipkart['Ram']=Ram\n",
    "flipkart['ROM']=ROM\n",
    "flipkart['Prim_Cam']=Prim_Cam\n",
    "flipkart['Sec_cam']=Sec_cam\n",
    "flipkart['Display']=Display\n",
    "flipkart['Resolution']=Resolution\n",
    "flipkart['Processor']=Processor\n",
    "flipkart['Cores']=Cores\n",
    "flipkart['Battery']=Battery\n",
    "flipkart['Prod_urls']=Prod_urls\n",
    "flipkart.to_csv('flipkart.csv')\n",
    "flipkart.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Write a program to scrap geospatial coordinates (latitude, longitude) of a city searched on google maps."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The latitude: 19.0820391 \n",
      "The Longitude: 72.6009774\n"
     ]
    }
   ],
   "source": [
    "#url\n",
    "driver.get(\"https://maps.google.com\")\n",
    "time.sleep(2)\n",
    "\n",
    "#accessing search bar\n",
    "\n",
    "search_bar=driver.find_element_by_xpath(\"/html/body/jsl/div[3]/div[9]/div[3]/div[1]/div[1]/div[1]/div[2]/form/div/div[3]/div/input[1]\")\n",
    "search_bar.send_keys(\"Mumbai\")\n",
    "time.sleep(3)\n",
    "\n",
    "#accessing search button\n",
    "\n",
    "search_button=driver.find_element_by_xpath(\"//*[@id='searchbox-searchbutton']\")\n",
    "search_button.click()\n",
    "time.sleep(2)\n",
    "\n",
    "\n",
    "#getting the url\n",
    "curr_url=driver.current_url\n",
    "url_list=curr_url.split('/')\n",
    "for i in url_list:\n",
    "    if '@' in i:\n",
    "        text=i\n",
    "lat_long=text.split(',')\n",
    "Latitude=lat_long[0].replace('@',\"\")\n",
    "Longitude=lat_long[1]\n",
    "\n",
    "print(\"The latitude:\",Latitude,\"\\nThe Longitude:\",Longitude)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Write a program to scrap details of all the funding deals for second quarter (i.e. July 20 –September 20) from trak.in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 485,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "driver.get('https://trak.in/')\n",
    "time.sleep(3)\n",
    "\n",
    "#clicking on funding details\n",
    "funding=driver.find_element_by_xpath(\"//*[@id='menu-item-51510']/a\")\n",
    "funding.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 599,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing each table on monthly base\n",
    "table_july=driver.find_elements_by_xpath('//table[@class=\"tablepress tablepress-id-48 dataTable no-footer\"]')\n",
    "table_aug=driver.find_elements_by_xpath('//table[@class=\"tablepress tablepress-id-49 dataTable no-footer\"]')\n",
    "table_sep=driver.find_elements_by_xpath('//table[@class=\"tablepress tablepress-id-50 dataTable no-footer\"]')\n",
    "Date=[]\n",
    "Company=[]\n",
    "Industry=[]\n",
    "Location=[]\n",
    "Subvertical=[]\n",
    "Investor=[]\n",
    "Investment_type=[]\n",
    "Amount=[]\n",
    "\n",
    "\n",
    "#Extracting from the July 2020 table\n",
    "for i in table_july:\n",
    "    date=i.find_elements_by_class_name(\"column-2\")\n",
    "    c_name=i.find_elements_by_class_name(\"column-3\")\n",
    "    Ind=i.find_elements_by_class_name(\"column-4\")\n",
    "    subvert=i.find_elements_by_class_name(\"column-5\")\n",
    "    loc=i.find_elements_by_class_name(\"column-6\")\n",
    "    investor=i.find_elements_by_class_name(\"column-7\")\n",
    "    invest_type=i.find_elements_by_class_name(\"column-8\")\n",
    "    amount=i.find_elements_by_class_name(\"column-9\")\n",
    "    \n",
    "for day in date:\n",
    "    Date.append(day.text)\n",
    "for company in c_name:\n",
    "    Company.append(company.text)\n",
    "for j in Ind:\n",
    "    Industry.append(j.text)\n",
    "for k in subvert:\n",
    "    Subvertical.append(k.text)\n",
    "for l in loc:\n",
    "    Location.append(l.text)\n",
    "for m in investor:\n",
    "    Investor.append(m.text)\n",
    "for n in invest_type:\n",
    "    Investment_type.append(n.text)\n",
    "for o in amount:\n",
    "    Amount.append(o.text)\n",
    "    \n",
    "#Extracting from the august 2020 table\n",
    "for i in table_aug:\n",
    "    date=i.find_elements_by_class_name(\"column-2\")\n",
    "    c_name=i.find_elements_by_class_name(\"column-3\")\n",
    "    Ind=i.find_elements_by_class_name(\"column-4\")\n",
    "    subvert=i.find_elements_by_class_name(\"column-5\")\n",
    "    loc=i.find_elements_by_class_name(\"column-6\")\n",
    "    investor=i.find_elements_by_class_name(\"column-7\")\n",
    "    invest_type=i.find_elements_by_class_name(\"column-8\")\n",
    "    amount=i.find_elements_by_class_name(\"column-9\")\n",
    "    \n",
    "for day in date:\n",
    "    Date.append(day.text)\n",
    "for company in c_name:\n",
    "    Company.append(company.text)\n",
    "for j in Ind:\n",
    "    Industry.append(j.text)\n",
    "for k in subvert:\n",
    "    Subvertical.append(k.text)\n",
    "for l in loc:\n",
    "    Location.append(l.text)\n",
    "for m in investor:\n",
    "    Investor.append(m.text)\n",
    "for n in invest_type:\n",
    "    Investment_type.append(n.text)\n",
    "for o in amount:\n",
    "    Amount.append(o.text)\n",
    "    \n",
    "    \n",
    "#Extracting from the Sep 2020 table    \n",
    "for i in table_sep:\n",
    "    date=i.find_elements_by_class_name(\"column-2\")\n",
    "    c_name=i.find_elements_by_class_name(\"column-3\")\n",
    "    Ind=i.find_elements_by_class_name(\"column-4\")\n",
    "    subvert=i.find_elements_by_class_name(\"column-5\")\n",
    "    loc=i.find_elements_by_class_name(\"column-6\")\n",
    "    investor=i.find_elements_by_class_name(\"column-7\")\n",
    "    invest_type=i.find_elements_by_class_name(\"column-8\")\n",
    "    amount=i.find_elements_by_class_name(\"column-9\")\n",
    "    \n",
    "for day in date:\n",
    "    Date.append(day.text)\n",
    "for company in c_name:\n",
    "    Company.append(company.text)\n",
    "for j in Ind:\n",
    "    Industry.append(j.text)\n",
    "for k in subvert:\n",
    "    Subvertical.append(k.text)\n",
    "for l in loc:\n",
    "    Location.append(l.text)\n",
    "for m in investor:\n",
    "    Investor.append(m.text)\n",
    "for n in invest_type:\n",
    "    Investment_type.append(n.text)\n",
    "for o in amount:\n",
    "    Amount.append(o.text)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 600,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Company</th>\n",
       "      <th>Industry</th>\n",
       "      <th>Location</th>\n",
       "      <th>Subvertical</th>\n",
       "      <th>Investor</th>\n",
       "      <th>Investment_type</th>\n",
       "      <th>Amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>Flipkart</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Walmart Inc</td>\n",
       "      <td>M&amp;A</td>\n",
       "      <td>1,200,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Vedantu</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Coatue Management</td>\n",
       "      <td>Series D</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Mystifly</td>\n",
       "      <td>Airfare Marketplace</td>\n",
       "      <td>Singapore and Bangalore</td>\n",
       "      <td>Ticketing, Airline Retailing, and Post-Ticketi...</td>\n",
       "      <td>Recruit Co. Ltd.</td>\n",
       "      <td>pre-Series B</td>\n",
       "      <td>3,300,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>goDutch</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Group Payments</td>\n",
       "      <td>Matrix India,Y Combinator, Global Founders Cap...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,700,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>10/07/2020</td>\n",
       "      <td>gigIndia</td>\n",
       "      <td>Marketplace</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Crowd Sourcing, Freelance</td>\n",
       "      <td>Incubate Fund India and Beyond Next Ventures</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>974,200</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>16/07/2020</td>\n",
       "      <td>Crio</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Learning Platform for Developers</td>\n",
       "      <td>021 Capital</td>\n",
       "      <td>pre-Series A</td>\n",
       "      <td>934,160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>13/07/2020</td>\n",
       "      <td>Open Appliances Pvt. Ltd.</td>\n",
       "      <td>Information Technology</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Internet-of-Things Security Solutions</td>\n",
       "      <td>Unicorn India Ventures</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>09/07/2020</td>\n",
       "      <td>JetSynthesys</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Pune</td>\n",
       "      <td>Gaming and Entertainment</td>\n",
       "      <td>Adar Poonawalla and Kris Gopalakrishnan.</td>\n",
       "      <td>Venture-Series Unknown</td>\n",
       "      <td>400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>15/07/2020</td>\n",
       "      <td>PumPumPum</td>\n",
       "      <td>Automotive Rental</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Used Car-leasing platform</td>\n",
       "      <td>Early Adapters Syndicate</td>\n",
       "      <td>Seed</td>\n",
       "      <td>292,800</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>14/07/2020</td>\n",
       "      <td>FLYX</td>\n",
       "      <td>OTT Player</td>\n",
       "      <td>New York and Delhi</td>\n",
       "      <td>Streaming Social Network</td>\n",
       "      <td>Raj Mishra, founder of AIT Global Inc</td>\n",
       "      <td>pre-Seed</td>\n",
       "      <td>200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>15/08/2020</td>\n",
       "      <td>Practo</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Health care and Wellness</td>\n",
       "      <td>A1A Company</td>\n",
       "      <td>Series F</td>\n",
       "      <td>32,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Medlife</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Prasid Uno Family Trust and SC Credit Fund</td>\n",
       "      <td></td>\n",
       "      <td>23,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>HungerBox</td>\n",
       "      <td>FoodTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Online Food Delivery Service</td>\n",
       "      <td>One97, Sabre Partners Trust, Pratithi Investme...</td>\n",
       "      <td>Series D1</td>\n",
       "      <td>1,560,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>04/08/2020</td>\n",
       "      <td>Dunzo</td>\n",
       "      <td>Hyper-local Logistics</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Online Delivery Services</td>\n",
       "      <td>Existing Backers</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>30,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>11/08/2020</td>\n",
       "      <td>Terra.do</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Stanford, California,</td>\n",
       "      <td>Online Climate School, E-learning</td>\n",
       "      <td>Stanford Angels and Entrepreneurs (India), BEE...</td>\n",
       "      <td>Seed</td>\n",
       "      <td>1,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>12/08/2020</td>\n",
       "      <td>Classplus</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Noida</td>\n",
       "      <td>E-learning, Online Tutoring</td>\n",
       "      <td>Falcon Edge</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>upto 15,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>14/08/2020</td>\n",
       "      <td>Niyo</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Niyo Solutions Inc.</td>\n",
       "      <td></td>\n",
       "      <td>6,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>10/08/2020</td>\n",
       "      <td>ZestMoney</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Primrose Hills Ventures</td>\n",
       "      <td></td>\n",
       "      <td>10,670,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>07/08/2020</td>\n",
       "      <td>FreshToHome</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Food Delivery</td>\n",
       "      <td>Ascent Capital</td>\n",
       "      <td>Venture</td>\n",
       "      <td>16,200,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>13/08/2020</td>\n",
       "      <td>Eduvanz</td>\n",
       "      <td>FinTech</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Financial Services</td>\n",
       "      <td>Sequoia India, Unitus</td>\n",
       "      <td>Series A</td>\n",
       "      <td>5,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>08/09/2020</td>\n",
       "      <td>Byju’s</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Online Tutoring</td>\n",
       "      <td>Silver Lake, Tiger Global, General Atlantic an...</td>\n",
       "      <td>Private Equity</td>\n",
       "      <td>500,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>12/09/2020</td>\n",
       "      <td>mCaffeine</td>\n",
       "      <td>Personal Care</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>Skincare &amp; Haircare</td>\n",
       "      <td>Amicus Capital Private Equity I LLP, Amicus Ca...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>3,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Qshala</td>\n",
       "      <td>EduTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Online Curiosity Platform for Kids</td>\n",
       "      <td>Rainmatter Capital</td>\n",
       "      <td>Angel</td>\n",
       "      <td>370,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>02/09/2020</td>\n",
       "      <td>Winzo</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>New Delhi</td>\n",
       "      <td>Online Gaming</td>\n",
       "      <td>Kalaari Capital Partners, IndigoEdge Managemen...</td>\n",
       "      <td>Series B</td>\n",
       "      <td>15,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>09/09/2020</td>\n",
       "      <td>Hippo Video</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Newark, Delaware, United States of Amercia</td>\n",
       "      <td>Video Customer Experience(CX) Platform</td>\n",
       "      <td>Alpha Wave Incubation, Exfinity Venture Partne...</td>\n",
       "      <td>Series A</td>\n",
       "      <td>4,500,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>Melorra</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Online Jewelry Store</td>\n",
       "      <td>Shadow Holdings, Lightbox.</td>\n",
       "      <td>Debt Financing</td>\n",
       "      <td>upto 8,900,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>07/09/2020</td>\n",
       "      <td>1mg</td>\n",
       "      <td>E-commerce</td>\n",
       "      <td>Gurgaon</td>\n",
       "      <td>Online Pharmacy</td>\n",
       "      <td>Gaja Capital, Tata Capital, Partners Group</td>\n",
       "      <td>In Progress</td>\n",
       "      <td>100,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>mfine</td>\n",
       "      <td>HealthTech</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>On-Demand Healthcare Services</td>\n",
       "      <td>Caretech Pte Inc</td>\n",
       "      <td>Series B</td>\n",
       "      <td>5,400,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>31/08/2020</td>\n",
       "      <td>Apna</td>\n",
       "      <td>Human Resources</td>\n",
       "      <td>Bangalore</td>\n",
       "      <td>Recruitment Platform</td>\n",
       "      <td>Lightspeed India and Sequoia Capital India</td>\n",
       "      <td>Series A</td>\n",
       "      <td>8,000,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>03/09/2020</td>\n",
       "      <td>Railofy</td>\n",
       "      <td>Transportation</td>\n",
       "      <td>Mumbai</td>\n",
       "      <td>WL &amp; RAC protection platform</td>\n",
       "      <td>Chiratae Ventures</td>\n",
       "      <td>Seed</td>\n",
       "      <td>950,000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          Date                    Company  \\\n",
       "0                                           \n",
       "1   15/07/2020                   Flipkart   \n",
       "2   16/07/2020                    Vedantu   \n",
       "3   13/07/2020                   Mystifly   \n",
       "4   14/07/2020                    goDutch   \n",
       "5   10/07/2020                   gigIndia   \n",
       "6   16/07/2020                       Crio   \n",
       "7   13/07/2020  Open Appliances Pvt. Ltd.   \n",
       "8   09/07/2020               JetSynthesys   \n",
       "9   15/07/2020                  PumPumPum   \n",
       "10  14/07/2020                       FLYX   \n",
       "11                                          \n",
       "12  15/08/2020                     Practo   \n",
       "13  13/08/2020                    Medlife   \n",
       "14  13/08/2020                  HungerBox   \n",
       "15  04/08/2020                      Dunzo   \n",
       "16  11/08/2020                   Terra.do   \n",
       "17  12/08/2020                  Classplus   \n",
       "18  14/08/2020                       Niyo   \n",
       "19  10/08/2020                  ZestMoney   \n",
       "20  07/08/2020                FreshToHome   \n",
       "21  13/08/2020                    Eduvanz   \n",
       "22                                          \n",
       "23  08/09/2020                     Byju’s   \n",
       "24  12/09/2020                  mCaffeine   \n",
       "25  09/09/2020                     Qshala   \n",
       "26  02/09/2020                      Winzo   \n",
       "27  09/09/2020                Hippo Video   \n",
       "28  07/09/2020                    Melorra   \n",
       "29  07/09/2020                        1mg   \n",
       "30  31/08/2020                      mfine   \n",
       "31  31/08/2020                       Apna   \n",
       "32  03/09/2020                    Railofy   \n",
       "\n",
       "                                  Industry  \\\n",
       "0                                            \n",
       "1                               E-commerce   \n",
       "2                                  EduTech   \n",
       "3                      Airfare Marketplace   \n",
       "4                                  FinTech   \n",
       "5                              Marketplace   \n",
       "6                                  EduTech   \n",
       "7                   Information Technology   \n",
       "8                 Gaming and Entertainment   \n",
       "9                        Automotive Rental   \n",
       "10                              OTT Player   \n",
       "11                                           \n",
       "12                              HealthTech   \n",
       "13                              E-commerce   \n",
       "14                                FoodTech   \n",
       "15                   Hyper-local Logistics   \n",
       "16                                 EduTech   \n",
       "17                                 EduTech   \n",
       "18                                 FinTech   \n",
       "19                                 FinTech   \n",
       "20                              E-commerce   \n",
       "21                                 FinTech   \n",
       "22                                           \n",
       "23                                 EduTech   \n",
       "24                           Personal Care   \n",
       "25                                 EduTech   \n",
       "26                           Online Gaming   \n",
       "27  Video Customer Experience(CX) Platform   \n",
       "28                              E-commerce   \n",
       "29                              E-commerce   \n",
       "30                              HealthTech   \n",
       "31                         Human Resources   \n",
       "32                          Transportation   \n",
       "\n",
       "                                      Location  \\\n",
       "0                                                \n",
       "1                                    Bangalore   \n",
       "2                                    Bangalore   \n",
       "3                      Singapore and Bangalore   \n",
       "4                                       Mumbai   \n",
       "5                                         Pune   \n",
       "6                                    Bangalore   \n",
       "7                                    Bangalore   \n",
       "8                                         Pune   \n",
       "9                                      Gurgaon   \n",
       "10                          New York and Delhi   \n",
       "11                                               \n",
       "12                                   Bangalore   \n",
       "13                                   Bangalore   \n",
       "14                                   Bangalore   \n",
       "15                                   Bangalore   \n",
       "16                       Stanford, California,   \n",
       "17                                       Noida   \n",
       "18                                   Bangalore   \n",
       "19                                   Bangalore   \n",
       "20                                   Bangalore   \n",
       "21                                      Mumbai   \n",
       "22                                               \n",
       "23                                   Bangalore   \n",
       "24                                      Mumbai   \n",
       "25                                   Bangalore   \n",
       "26                                   New Delhi   \n",
       "27  Newark, Delaware, United States of Amercia   \n",
       "28                                   Bangalore   \n",
       "29                                     Gurgaon   \n",
       "30                                   Bangalore   \n",
       "31                                   Bangalore   \n",
       "32                                      Mumbai   \n",
       "\n",
       "                                          Subvertical  \\\n",
       "0                                                       \n",
       "1                                          E-commerce   \n",
       "2                                     Online Tutoring   \n",
       "3   Ticketing, Airline Retailing, and Post-Ticketi...   \n",
       "4                                      Group Payments   \n",
       "5                           Crowd Sourcing, Freelance   \n",
       "6                    Learning Platform for Developers   \n",
       "7               Internet-of-Things Security Solutions   \n",
       "8                            Gaming and Entertainment   \n",
       "9                           Used Car-leasing platform   \n",
       "10                           Streaming Social Network   \n",
       "11                                                      \n",
       "12                           Health care and Wellness   \n",
       "13                                    Online Pharmacy   \n",
       "14                       Online Food Delivery Service   \n",
       "15                           Online Delivery Services   \n",
       "16                  Online Climate School, E-learning   \n",
       "17                        E-learning, Online Tutoring   \n",
       "18                                 Financial Services   \n",
       "19                                 Financial Services   \n",
       "20                                      Food Delivery   \n",
       "21                                 Financial Services   \n",
       "22                                                      \n",
       "23                                    Online Tutoring   \n",
       "24                                Skincare & Haircare   \n",
       "25                 Online Curiosity Platform for Kids   \n",
       "26                                      Online Gaming   \n",
       "27             Video Customer Experience(CX) Platform   \n",
       "28                               Online Jewelry Store   \n",
       "29                                    Online Pharmacy   \n",
       "30                      On-Demand Healthcare Services   \n",
       "31                               Recruitment Platform   \n",
       "32                       WL & RAC protection platform   \n",
       "\n",
       "                                             Investor         Investment_type  \\\n",
       "0                                                                               \n",
       "1                                         Walmart Inc                     M&A   \n",
       "2                                   Coatue Management                Series D   \n",
       "3                                    Recruit Co. Ltd.            pre-Series B   \n",
       "4   Matrix India,Y Combinator, Global Founders Cap...                    Seed   \n",
       "5        Incubate Fund India and Beyond Next Ventures            pre-Series A   \n",
       "6                                         021 Capital            pre-Series A   \n",
       "7                              Unicorn India Ventures  Venture-Series Unknown   \n",
       "8            Adar Poonawalla and Kris Gopalakrishnan.  Venture-Series Unknown   \n",
       "9                            Early Adapters Syndicate                    Seed   \n",
       "10              Raj Mishra, founder of AIT Global Inc                pre-Seed   \n",
       "11                                                                              \n",
       "12                                        A1A Company                Series F   \n",
       "13         Prasid Uno Family Trust and SC Credit Fund                           \n",
       "14  One97, Sabre Partners Trust, Pratithi Investme...               Series D1   \n",
       "15                                   Existing Backers             In Progress   \n",
       "16  Stanford Angels and Entrepreneurs (India), BEE...                    Seed   \n",
       "17                                        Falcon Edge             In Progress   \n",
       "18                                Niyo Solutions Inc.                           \n",
       "19                            Primrose Hills Ventures                           \n",
       "20                                     Ascent Capital                 Venture   \n",
       "21                              Sequoia India, Unitus                Series A   \n",
       "22                                                                              \n",
       "23  Silver Lake, Tiger Global, General Atlantic an...          Private Equity   \n",
       "24  Amicus Capital Private Equity I LLP, Amicus Ca...                Series B   \n",
       "25                                 Rainmatter Capital                   Angel   \n",
       "26  Kalaari Capital Partners, IndigoEdge Managemen...                Series B   \n",
       "27  Alpha Wave Incubation, Exfinity Venture Partne...                Series A   \n",
       "28                         Shadow Holdings, Lightbox.          Debt Financing   \n",
       "29         Gaja Capital, Tata Capital, Partners Group             In Progress   \n",
       "30                                   Caretech Pte Inc                Series B   \n",
       "31         Lightspeed India and Sequoia Capital India                Series A   \n",
       "32                                  Chiratae Ventures                    Seed   \n",
       "\n",
       "             Amount  \n",
       "0                    \n",
       "1     1,200,000,000  \n",
       "2       100,000,000  \n",
       "3         3,300,000  \n",
       "4         1,700,000  \n",
       "5           974,200  \n",
       "6           934,160  \n",
       "7           500,000  \n",
       "8           400,000  \n",
       "9           292,800  \n",
       "10          200,000  \n",
       "11                   \n",
       "12       32,000,000  \n",
       "13       23,000,000  \n",
       "14        1,560,000  \n",
       "15       30,000,000  \n",
       "16        1,400,000  \n",
       "17  upto 15,000,000  \n",
       "18        6,000,000  \n",
       "19       10,670,000  \n",
       "20       16,200,000  \n",
       "21        5,000,000  \n",
       "22                   \n",
       "23      500,000,000  \n",
       "24        3,000,000  \n",
       "25          370,000  \n",
       "26       15,500,000  \n",
       "27        4,500,000  \n",
       "28   upto 8,900,000  \n",
       "29      100,000,000  \n",
       "30        5,400,000  \n",
       "31        8,000,000  \n",
       "32          950,000  "
      ]
     },
     "execution_count": 600,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Trak=pd.DataFrame({})\n",
    "Trak['Date']=Date\n",
    "Trak['Company']=Company\n",
    "Trak['Industry']=Industry\n",
    "Trak['Location']=Location\n",
    "Trak['Subvertical']=Subvertical\n",
    "Trak['Investor']=Investor\n",
    "Trak['Investment_type']=Investment_type\n",
    "Trak['Amount']=Amount\n",
    "Trak"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Write a program to scrap all the available details of best gaming laptops from digit.in. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 453,
   "metadata": {},
   "outputs": [],
   "source": [
    "# accessing url\n",
    "url = \"https://www.digit.in/\"\n",
    "driver.get(url)\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking on top 10\n",
    "top_10=driver.find_element_by_xpath(\"/html/body/div[1]/div[2]/div[4]/ul/li[4]/a\")\n",
    "top_10.click()\n",
    "time.sleep(2)\n",
    "\n",
    "#clicking laprops\n",
    "laptops=driver.find_element_by_xpath(\"/html/body/div[3]/div/div/div[2]/div[5]/div[1]/div/button[2]/img\")\n",
    "laptops.click()\n",
    "\n",
    "#clicking on  the gaming laptops\n",
    "\n",
    "best_gaming=driver.find_element_by_xpath(\"//div[@id='laptops']//div[3]//a\")\n",
    "driver.get(best_gaming.get_attribute('href'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "metadata": {},
   "outputs": [],
   "source": [
    "#creating lsits\n",
    "name = []\n",
    "Price = []\n",
    "OS = []\n",
    "display = []\n",
    "processor = []\n",
    "HDD = []\n",
    "RAM = []\n",
    "weight = []\n",
    "dimension = []\n",
    "GPU = []\n",
    "\n",
    "time.sleep(1)\n",
    "#names\n",
    "names=driver.find_elements_by_xpath(\"//div[@class='right-container']/div/a/h3\")\n",
    "for i in names:\n",
    "    name.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "#operating system\n",
    "os=driver.find_elements_by_xpath(\"//div[@class='product-detail']/div/ul/li[1]/div/div\")\n",
    "for i in os:\n",
    "    OS.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "#scraping display\n",
    "displays=driver.find_elements_by_xpath(\"//div[@class='product-detail']/div/ul/li[2]/div/div\")\n",
    "for i in displays:\n",
    "    display.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "# processor\n",
    "processors=driver.find_elements_by_xpath(\"//div[@class='product-detail']/div/ul/li[3]/div/div\")\n",
    "for i in processors:\n",
    "    processor.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "# scraping memory\n",
    "memories=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[6]/td[3]\")# extrat HDD and RAM form xpath\n",
    "for i in memories:\n",
    "    HDD.append(i.text.split(\"/\")[0])\n",
    "    RAM.append(i.text.split(\"/\")[1])\n",
    "\n",
    "time.sleep(1)\n",
    "# scraping weight\n",
    "weights=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[7]/td[3]\")# extrat weight form xpath\n",
    "for i in weights:\n",
    "    weight.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "# scraping dimension\n",
    "dimension=[]\n",
    "dimensions=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[8]/td[3]\") \n",
    "for i in dimensions:\n",
    "    dimension.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "# scraping graphical processor\n",
    "GPUs=driver.find_elements_by_xpath(\"//div[@class='Spcs-details'][1]/table/tbody/tr[9]/td[3]\") \n",
    "for i in GPUs:\n",
    "    GPU.append(i.text)\n",
    "\n",
    "time.sleep(1)\n",
    "\n",
    "#scraping price\n",
    "price=driver.find_elements_by_xpath(\"//table[@id='summtable']//tr//td[3]\")\n",
    "for i in price:\n",
    "    Price.append(i.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 456,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>price</th>\n",
       "      <th>OS</th>\n",
       "      <th>Display</th>\n",
       "      <th>HDD</th>\n",
       "      <th>RAM</th>\n",
       "      <th>processor</th>\n",
       "      <th>weight</th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Graphical processor</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>ALIENWARE AREA 51M R2</td>\n",
       "      <td>N/A</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>17.3\" (1920 X 1080)</td>\n",
       "      <td>1 TB SSD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>10TH GENERATION INTEL® CORE™ I7-10700 | 2.90 GHZ</td>\n",
       "      <td>4.1</td>\n",
       "      <td>27.65 x 402.6 x 319.14</td>\n",
       "      <td>Intel® UHD Graphics 630</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>ALIENWARE M15 R3</td>\n",
       "      <td>₹341990</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>15.6\" (3840 X 2160)</td>\n",
       "      <td>1 TB SSD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>10TH GENERATION INTEL® CORE™ I9-10980HK | NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ASUS ROG STRIX SCAR 15</td>\n",
       "      <td>N/A</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>1 TB SSD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>AMD RYZEN™ 9 5900HX | 3.3 GHZ</td>\n",
       "      <td>2.30</td>\n",
       "      <td>35.4 x 25.9 x 2.26</td>\n",
       "      <td>NVIDIA® GeForce RTX™ 3070</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>ASUS ROG ZEPHYRUS G14</td>\n",
       "      <td>₹164990</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>14\" (1920 X 1080)</td>\n",
       "      <td>1 TB SSD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>AMD 3RD GENERATION RYZEN 9 | 3.3 GHZ</td>\n",
       "      <td>1.65</td>\n",
       "      <td>32.5 x 22.1 x 1.8</td>\n",
       "      <td>NVIDIA GeForce RTX 2060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>LENOVO LEGION 5I</td>\n",
       "      <td>₹71990</td>\n",
       "      <td>WINDOWS 10 PRO</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>1 TB SSD</td>\n",
       "      <td>16 GBGB DDR4</td>\n",
       "      <td>10TH GENERATION INTEL® CORE™ I5-10300H | 2.50 GHZ</td>\n",
       "      <td>2.3</td>\n",
       "      <td>363.06 x 259.61 x 23.57</td>\n",
       "      <td>NVIDIA® GeForce® GTX 1650 4GB</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>ASUS ROG ZEPHYRUS DUO 15</td>\n",
       "      <td>₹173800</td>\n",
       "      <td>WINDOWS 10</td>\n",
       "      <td>15.6\" (3840 X 1100)</td>\n",
       "      <td>512 GB SSD</td>\n",
       "      <td>4 GBGB DDR4</td>\n",
       "      <td>INTEL CORE I7 10TH GEN 10875H | NA</td>\n",
       "      <td>2.4</td>\n",
       "      <td>268.30 x 360.00 x 20.90</td>\n",
       "      <td>NVIDIA GeForce RTX 2070 Max-Q</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>ACER ASPIRE 7 GAMING</td>\n",
       "      <td>₹56990</td>\n",
       "      <td>WINDOWS 10 HOME</td>\n",
       "      <td>15.6\" (1920 X 1080)</td>\n",
       "      <td>512 GB SSD</td>\n",
       "      <td>8 GBGB DDR4</td>\n",
       "      <td>AMD RYZEN™ 5-5500U HEXA-CORE | NA</td>\n",
       "      <td>2.15</td>\n",
       "      <td>2.29 x 36.3 x 25.4</td>\n",
       "      <td>NVIDIA® GeForce® GTX 1650</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                       Name    price               OS              Display  \\\n",
       "0     ALIENWARE AREA 51M R2      N/A  WINDOWS 10 HOME  17.3\" (1920 X 1080)   \n",
       "1          ALIENWARE M15 R3  ₹341990  WINDOWS 10 HOME  15.6\" (3840 X 2160)   \n",
       "2    ASUS ROG STRIX SCAR 15      N/A  WINDOWS 10 HOME  15.6\" (1920 X 1080)   \n",
       "3     ASUS ROG ZEPHYRUS G14  ₹164990  WINDOWS 10 HOME    14\" (1920 X 1080)   \n",
       "4          LENOVO LEGION 5I   ₹71990   WINDOWS 10 PRO  15.6\" (1920 X 1080)   \n",
       "5  ASUS ROG ZEPHYRUS DUO 15  ₹173800       WINDOWS 10  15.6\" (3840 X 1100)   \n",
       "6      ACER ASPIRE 7 GAMING   ₹56990  WINDOWS 10 HOME  15.6\" (1920 X 1080)   \n",
       "\n",
       "          HDD           RAM  \\\n",
       "0    1 TB SSD  16 GBGB DDR4   \n",
       "1    1 TB SSD  16 GBGB DDR4   \n",
       "2    1 TB SSD  16 GBGB DDR4   \n",
       "3    1 TB SSD  16 GBGB DDR4   \n",
       "4    1 TB SSD  16 GBGB DDR4   \n",
       "5  512 GB SSD   4 GBGB DDR4   \n",
       "6  512 GB SSD   8 GBGB DDR4   \n",
       "\n",
       "                                           processor weight  \\\n",
       "0   10TH GENERATION INTEL® CORE™ I7-10700 | 2.90 GHZ    4.1   \n",
       "1       10TH GENERATION INTEL® CORE™ I9-10980HK | NA     NA   \n",
       "2                      AMD RYZEN™ 9 5900HX | 3.3 GHZ   2.30   \n",
       "3               AMD 3RD GENERATION RYZEN 9 | 3.3 GHZ   1.65   \n",
       "4  10TH GENERATION INTEL® CORE™ I5-10300H | 2.50 GHZ    2.3   \n",
       "5                 INTEL CORE I7 10TH GEN 10875H | NA    2.4   \n",
       "6                  AMD RYZEN™ 5-5500U HEXA-CORE | NA   2.15   \n",
       "\n",
       "                 Dimension            Graphical processor  \n",
       "0   27.65 x 402.6 x 319.14        Intel® UHD Graphics 630  \n",
       "1                       NA                             NA  \n",
       "2       35.4 x 25.9 x 2.26      NVIDIA® GeForce RTX™ 3070  \n",
       "3        32.5 x 22.1 x 1.8        NVIDIA GeForce RTX 2060  \n",
       "4  363.06 x 259.61 x 23.57  NVIDIA® GeForce® GTX 1650 4GB  \n",
       "5  268.30 x 360.00 x 20.90  NVIDIA GeForce RTX 2070 Max-Q  \n",
       "6       2.29 x 36.3 x 25.4      NVIDIA® GeForce® GTX 1650  "
      ]
     },
     "execution_count": 456,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Best_gaming=pd.DataFrame({})\n",
    "Best_gaming[\"Name\"]=name\n",
    "Best_gaming[\"price\"]=Price\n",
    "Best_gaming[\"OS\"]=OS\n",
    "Best_gaming[\"Display\"]=display\n",
    "Best_gaming[\"HDD\"]=HDD\n",
    "Best_gaming[\"RAM\"]=RAM\n",
    "Best_gaming[\"processor\"]=processor\n",
    "Best_gaming[\"weight\"]=weight\n",
    "Best_gaming[\"Dimension\"]=dimension\n",
    "Best_gaming[\"Graphical processor\"]=GPU\n",
    "Best_gaming"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 8. Write a python program to scrape the details for all billionaires from www.forbes.com. Details to be scrapped: “Rank”, “Name”, “Net worth”, “Age”, “Citizenship”, “Source”,“Industry”.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 601,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "driver.get('https://www.forbes.com/billionaires/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 605,
   "metadata": {},
   "outputs": [],
   "source": [
    "Rank=[]\n",
    "Names=[]\n",
    "Net_worth=[]\n",
    "Age=[]\n",
    "Citizenship=[]\n",
    "Source=[]\n",
    "Industry=[]\n",
    "Rank_list=driver.find_elements_by_xpath(\"//div[@class='rank']\")\n",
    "Name_list=driver.find_elements_by_xpath(\"//div[@class='personName']\")\n",
    "worth_list=driver.find_elements_by_xpath(\"//div[@class='netWorth']\")\n",
    "age=driver.find_elements_by_xpath(\"//div[@class='age']\")\n",
    "source=driver.find_elements_by_xpath(\"//div[@class='source-column']\")\n",
    "country=driver.find_elements_by_xpath(\"//div[@class='countryOfCitizenship']\")\n",
    "industry=driver.find_elements_by_xpath(\"//div[@class='category']\")\n",
    "for name in Name_list:\n",
    "    Names.append(name.text)\n",
    "for rank in Rank_list:\n",
    "    Rank.append(rank.text)\n",
    "for worth in worth_list:\n",
    "    Net_worth.append(worth.text)\n",
    "for ag in age:\n",
    "    Age.append(ag.text)\n",
    "for src in source:\n",
    "    Source.append(src.text)\n",
    "for orgin in country:\n",
    "    Citizenship.append(orgin.text)\n",
    "for ind in industry:\n",
    "    Industry.append(ind.text)\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 606,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Names</th>\n",
       "      <th>Net_worth</th>\n",
       "      <th>Age</th>\n",
       "      <th>Citizenship</th>\n",
       "      <th>Source</th>\n",
       "      <th>Industry</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.</td>\n",
       "      <td>Jeff Bezos</td>\n",
       "      <td>$177 B</td>\n",
       "      <td>57</td>\n",
       "      <td>United States</td>\n",
       "      <td>Amazon</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.</td>\n",
       "      <td>Elon Musk</td>\n",
       "      <td>$151 B</td>\n",
       "      <td>49</td>\n",
       "      <td>United States</td>\n",
       "      <td>Tesla, SpaceX</td>\n",
       "      <td>Automotive</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3.</td>\n",
       "      <td>Bernard Arnault &amp; family</td>\n",
       "      <td>$150 B</td>\n",
       "      <td>72</td>\n",
       "      <td>France</td>\n",
       "      <td>LVMH</td>\n",
       "      <td>Fashion &amp; Retail</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4.</td>\n",
       "      <td>Bill Gates</td>\n",
       "      <td>$124 B</td>\n",
       "      <td>65</td>\n",
       "      <td>United States</td>\n",
       "      <td>Microsoft</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.</td>\n",
       "      <td>Mark Zuckerberg</td>\n",
       "      <td>$97 B</td>\n",
       "      <td>36</td>\n",
       "      <td>United States</td>\n",
       "      <td>Facebook</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195.</td>\n",
       "      <td>Harry Triguboff</td>\n",
       "      <td>$11.2 B</td>\n",
       "      <td>88</td>\n",
       "      <td>Australia</td>\n",
       "      <td>real estate</td>\n",
       "      <td>Real Estate</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>197.</td>\n",
       "      <td>Leonid Fedun &amp; family</td>\n",
       "      <td>$11.1 B</td>\n",
       "      <td>65</td>\n",
       "      <td>Russia</td>\n",
       "      <td>oil</td>\n",
       "      <td>Energy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197.</td>\n",
       "      <td>Eyal Ofer</td>\n",
       "      <td>$11.1 B</td>\n",
       "      <td>70</td>\n",
       "      <td>Israel</td>\n",
       "      <td>real estate, shipping</td>\n",
       "      <td>Diversified</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>197.</td>\n",
       "      <td>Evan Spiegel</td>\n",
       "      <td>$11.1 B</td>\n",
       "      <td>30</td>\n",
       "      <td>United States</td>\n",
       "      <td>Snapchat</td>\n",
       "      <td>Technology</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>200.</td>\n",
       "      <td>Luis Carlos Sarmiento</td>\n",
       "      <td>$11 B</td>\n",
       "      <td>88</td>\n",
       "      <td>Colombia</td>\n",
       "      <td>banking</td>\n",
       "      <td>Finance &amp; Investments</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>200 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank                     Names Net_worth Age    Citizenship  \\\n",
       "0      1.                Jeff Bezos    $177 B  57  United States   \n",
       "1      2.                 Elon Musk    $151 B  49  United States   \n",
       "2      3.  Bernard Arnault & family    $150 B  72         France   \n",
       "3      4.                Bill Gates    $124 B  65  United States   \n",
       "4      5.           Mark Zuckerberg     $97 B  36  United States   \n",
       "..    ...                       ...       ...  ..            ...   \n",
       "195  195.           Harry Triguboff   $11.2 B  88      Australia   \n",
       "196  197.     Leonid Fedun & family   $11.1 B  65         Russia   \n",
       "197  197.                 Eyal Ofer   $11.1 B  70         Israel   \n",
       "198  197.              Evan Spiegel   $11.1 B  30  United States   \n",
       "199  200.     Luis Carlos Sarmiento     $11 B  88       Colombia   \n",
       "\n",
       "                    Source               Industry  \n",
       "0                   Amazon             Technology  \n",
       "1            Tesla, SpaceX             Automotive  \n",
       "2                     LVMH       Fashion & Retail  \n",
       "3                Microsoft             Technology  \n",
       "4                 Facebook             Technology  \n",
       "..                     ...                    ...  \n",
       "195            real estate            Real Estate  \n",
       "196                    oil                 Energy  \n",
       "197  real estate, shipping            Diversified  \n",
       "198               Snapchat             Technology  \n",
       "199                banking  Finance & Investments  \n",
       "\n",
       "[200 rows x 7 columns]"
      ]
     },
     "execution_count": 606,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Billionares=pd.DataFrame({})\n",
    "Billionares['Rank']=Rank\n",
    "Billionares['Names']=Names\n",
    "Billionares['Net_worth']=Net_worth\n",
    "Billionares['Age']=Age\n",
    "Billionares['Citizenship']=Citizenship\n",
    "Billionares['Source']=Source\n",
    "Billionares['Industry']=Industry\n",
    "Billionares\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 9. Write a program to extract at least 500 Comments, Comment upvote and time when comment was posted from any YouTube Video.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing url\n",
    "driver.get('https://www.youtube.com/watch?v=dFCbJmgeHmA')\n",
    "time.sleep(3)\n",
    "for i in range(180):\n",
    "    time.sleep(5)\n",
    "    driver.execute_script(\"window.scrollBy(0,350)\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "comments=[]\n",
    "Upvotes=[]\n",
    "Posted=[]\n",
    "\n",
    "\n",
    "#getting comments,Likes and Date\n",
    "comment_list=driver.find_elements_by_xpath(\"//yt-formatted-string[@class='style-scope ytd-comment-renderer']\")\n",
    "\n",
    "posted=driver.find_elements_by_xpath(\"//yt-formatted-string[@class='published-time-text above-comment style-scope ytd-comment-renderer']//a\")\n",
    "\n",
    "#comments to list\n",
    "item=''\n",
    "comments=[i.text.lstrip() for i in comment_list]\n",
    "\n",
    "comments_n = [i for i in comments if i != item]\n",
    "\n",
    "comments_n\n",
    "\n",
    "\n",
    "#upvotes to list\n",
    "\n",
    "#toolbar\n",
    "toolbar=driver.find_elements_by_id(\"toolbar\")\n",
    "for i in toolbar:\n",
    "    try:\n",
    "        Likes=i.find_element_by_id(\"vote-count-middle\")\n",
    "        if Likes is None:\n",
    "            Upvotes.append(0)\n",
    "        else:\n",
    "            Upvotes.append(Likes.text)   \n",
    "        \n",
    "    except NoSuchElementException:\n",
    "        Upvotes.append(0)\n",
    "\n",
    "\n",
    "#psted date to list\n",
    "Posted=[j.text for j in posted]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "#replacing empty values by 0\n",
    "for n, i in enumerate(Upvotes):\n",
    " if i == '':\n",
    "    Upvotes[n] = '0'\n",
    "#cleaning comments\n",
    "comments_n\n",
    "comments_n=[i.replace('\\n','') for i in comments_n]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Comments</th>\n",
       "      <th>Upvotes</th>\n",
       "      <th>Date_posted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ohai! So a few more words about our announceme...</td>\n",
       "      <td>14K</td>\n",
       "      <td>2 weeks ago (edited)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>When he said \"Yeeted into space\" I had to rewi...</td>\n",
       "      <td>35K</td>\n",
       "      <td>2 weeks ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>It's frightening how an entire era disappeared...</td>\n",
       "      <td>1.4K</td>\n",
       "      <td>6 days ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>The most scientific term you will EVER hear:\"T...</td>\n",
       "      <td>1.2K</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>”Long ago, the dinosaurs lived together in har...</td>\n",
       "      <td>415</td>\n",
       "      <td>1 week ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            Comments Upvotes  \\\n",
       "0  Ohai! So a few more words about our announceme...     14K   \n",
       "1  When he said \"Yeeted into space\" I had to rewi...     35K   \n",
       "2  It's frightening how an entire era disappeared...    1.4K   \n",
       "3  The most scientific term you will EVER hear:\"T...    1.2K   \n",
       "4  ”Long ago, the dinosaurs lived together in har...     415   \n",
       "\n",
       "            Date_posted  \n",
       "0  2 weeks ago (edited)  \n",
       "1           2 weeks ago  \n",
       "2            6 days ago  \n",
       "3            1 week ago  \n",
       "4            1 week ago  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Youtube=pd.DataFrame({})\n",
    "Youtube['Comments']=comments_n[:500]\n",
    "Youtube['Upvotes']=Upvotes[:500]\n",
    "Youtube['Date_posted']=Posted[:500]\n",
    "Youtube.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 10. Write a python program to scrape a data for all available Hostels from\n",
    "https://www.hostelworld.com/ in “London” location. You have to scrape hostel name,\n",
    "distance from city centre, ratings, total reviews, overall reviews, privates from price, dorms\n",
    "from price, facilities and property description. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 322,
   "metadata": {},
   "outputs": [],
   "source": [
    "#getting url\n",
    "driver.get('https://www.hostelworld.com/')\n",
    "time.sleep(4)\n",
    "\n",
    "#clicking the search field to enable locating the search bar element\n",
    "random=driver.find_element_by_xpath(\"//div[@class='field body-2 location-input']\")\n",
    "random.click()\n",
    "time.sleep(3)\n",
    "\n",
    "#search_bar\n",
    "search=driver.find_element_by_xpath(\"//input[@class='search-input']\")\n",
    "time.sleep(2)\n",
    "search.send_keys('London')\n",
    "time.sleep(2)\n",
    "\n",
    "#selecting the first suggetion\n",
    "select=driver.find_element_by_xpath('//*[@id=\"predicted-search-results\"]/li[2]')\n",
    "select.click()\n",
    "\n",
    "#search_button- clicking twice to minimize the suggetions\n",
    "search_btn=driver.find_element_by_id(\"search-button\")\n",
    "for i in range(1):\n",
    "    search_btn.click()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "#accessing and extracting page urls\n",
    "page_urls=[]\n",
    "##Name=[]\n",
    "time.sleep(4)\n",
    "for page in range(0,3):\n",
    "    driver.execute_script(\"window.scrollBy(0,350)\")\n",
    "    page_urls.append(driver.current_url)\n",
    "    time.sleep(5)\n",
    "    try:\n",
    "        next= driver.find_element_by_xpath(\"//i[@class='core-icon icon-core-chevron-right']\")\n",
    "        next.click()\n",
    "    except:\n",
    "         pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 436,
   "metadata": {},
   "outputs": [],
   "source": [
    "Name=[]\n",
    "distance=[]\n",
    "Ratings=[]\n",
    "Private=[]\n",
    "Dorms=[]\n",
    "Facility=[]\n",
    "for url in page_urls:\n",
    "    driver.get(url)\n",
    "    time.sleep(2)\n",
    "    \n",
    "    #name of the hostel\n",
    "    name=driver.find_elements_by_xpath(\"//h2[@class='title title-6']//a\") #extracting the details frm each page\n",
    "    for i in name:\n",
    "        Name.append(i.text)\n",
    "        \n",
    "    #distance\n",
    "    dist=driver.find_elements_by_xpath(\"//span[@class='description']\")\n",
    "    for d in dist:\n",
    "        distance.append(d.text)\n",
    "    \n",
    "    #ratings\n",
    "    try:\n",
    "        rate=driver.find_elements_by_xpath(\"//div[@class='rating rating-summary-container big']\")\n",
    "        for r in rate:\n",
    "            Ratings.append(r.text)\n",
    "    except:\n",
    "        rate=driver.find_elements_by_xpath(\"//div[@class='keyword']\")\n",
    "        for r in rate:\n",
    "            Ratings.append(r.text)\n",
    "            \n",
    "    #private pricing\n",
    "    private=driver.find_elements_by_xpath(\"//a[@class='prices']\")\n",
    "    for p in private:\n",
    "            Private.append(p.text)\n",
    "    facilities=driver.find_elements_by_xpath(\"//div[@class='facilities-label facilities']\")\n",
    "    for f in facilities:\n",
    "            Facility.append(f.text.replace('\\n',','))  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 446,
   "metadata": {},
   "outputs": [],
   "source": [
    "Numer_Rating=[]\n",
    "Total_Ratings=[]\n",
    "overall=[]\n",
    "private_rooms=[]\n",
    "dorm_rooms=[]\n",
    "pvt=[]\n",
    "description=[]\n",
    "Distance=[]\n",
    "#extracting the rating\n",
    "for num in Ratings:       \n",
    "    Numer_Rating.append(num.split(\"\\n\")[0])\n",
    "    \n",
    "\n",
    "#extracting total ratings\n",
    "for tot in Ratings:\n",
    "    Total_Ratings.append(tot.split('\\n')[-1])\n",
    "    \n",
    "    \n",
    "#extracting the overall ratings\n",
    "rating=[i.split('\\n') for i in Ratings]\n",
    "\n",
    "for i in rating:\n",
    "    if len(i)==2:\n",
    "        overall.append('No rating')\n",
    "    else:\n",
    "        overall.append(i[1])\n",
    "    \n",
    "p_list=Private[3:]        #removing junk values\n",
    "price=[i.split('\\n') for i in p_list]\n",
    "\n",
    "#Accessing the private room prices\n",
    "for i in price:\n",
    "    if len(i)==4:\n",
    "        private_rooms.append(i[1])\n",
    "    elif i[0]==\"Privates From\":\n",
    "        private_rooms.append(i[1])\n",
    "    else:\n",
    "        private_rooms.append(\"No Private Rooms\")\n",
    "\n",
    "#Accessing the Dorm room prices\n",
    "for j in price:\n",
    "    if len(j)==4:\n",
    "        dorm_rooms.append(j[3])\n",
    "    elif j[1]==\"Dorms From\":\n",
    "        dorm_rooms.append(j[2])\n",
    "    else:\n",
    "        dorm_rooms.append(\"No Dorm Rooms\")\n",
    "        \n",
    "        \n",
    "#extracting Description and distance\n",
    "for i in distance:\n",
    "    description.append(i.split('-')[0].strip())\n",
    "for d in distance:\n",
    "    Distance.append(d.split('-')[1].strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 445,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Name</th>\n",
       "      <th>Distance from city</th>\n",
       "      <th>Private_rooms</th>\n",
       "      <th>Dorm_rooms</th>\n",
       "      <th>Facility</th>\n",
       "      <th>Description</th>\n",
       "      <th>Rating</th>\n",
       "      <th>Reviews</th>\n",
       "      <th>total reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>St Christopher's Village</td>\n",
       "      <td>1.8km from city centre</td>\n",
       "      <td>Rs3408</td>\n",
       "      <td>Rs1435</td>\n",
       "      <td>Free WiFi,Follows Covid-19 sanitation guidance</td>\n",
       "      <td>Hostel</td>\n",
       "      <td>8.9</td>\n",
       "      <td>Fabulous</td>\n",
       "      <td>10814 Total Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Generator London</td>\n",
       "      <td>3km from city centre</td>\n",
       "      <td>Rs8571</td>\n",
       "      <td>Rs2169</td>\n",
       "      <td>Free WiFi,Follows Covid-19 sanitation guidance</td>\n",
       "      <td>Hostel</td>\n",
       "      <td>7.5</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>6729 Total Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Safestay London Kensington Holland Park</td>\n",
       "      <td>5.9km from city centre</td>\n",
       "      <td>Rs4180</td>\n",
       "      <td>Rs1022</td>\n",
       "      <td>Free WiFi</td>\n",
       "      <td>Hostel</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>1070 Total Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PubLove @ The Crown, Battersea</td>\n",
       "      <td>4.7km from city centre</td>\n",
       "      <td>No Private Rooms</td>\n",
       "      <td>Rs1239</td>\n",
       "      <td>Free WiFi,Follows Covid-19 sanitation guidance</td>\n",
       "      <td>Hostel</td>\n",
       "      <td>7.9</td>\n",
       "      <td>Very Good</td>\n",
       "      <td>204 Total Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Leman House</td>\n",
       "      <td>3.6km from city centre</td>\n",
       "      <td>Rs5577</td>\n",
       "      <td>No Dorm Rooms</td>\n",
       "      <td>Free WiFi</td>\n",
       "      <td>Hostel</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>No rating</td>\n",
       "      <td>13 Total Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>80</th>\n",
       "      <td>The Dover</td>\n",
       "      <td>1.9km from city centre</td>\n",
       "      <td>Rs6747</td>\n",
       "      <td>No Dorm Rooms</td>\n",
       "      <td>Free WiFi,Free Breakfast</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>No rating</td>\n",
       "      <td>4 Total Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>81</th>\n",
       "      <td>Park Hotel Essex</td>\n",
       "      <td>24.1km from city centre</td>\n",
       "      <td>Rs3752</td>\n",
       "      <td>No Dorm Rooms</td>\n",
       "      <td>Free Breakfast,Follows Covid-19 sanitation gui...</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>No rating</td>\n",
       "      <td>108 Total Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82</th>\n",
       "      <td>Cranbrook Hotel</td>\n",
       "      <td>14.8km from city centre</td>\n",
       "      <td>Rs3098</td>\n",
       "      <td>No Dorm Rooms</td>\n",
       "      <td>Free Breakfast,Follows Covid-19 sanitation gui...</td>\n",
       "      <td>Hotel</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>No rating</td>\n",
       "      <td>58 Total Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>St. Athans</td>\n",
       "      <td>2.9km from city centre</td>\n",
       "      <td>Rs3976</td>\n",
       "      <td>No Dorm Rooms</td>\n",
       "      <td>Free WiFi,Follows Covid-19 sanitation guidance</td>\n",
       "      <td>Bed and Breakfast</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>No rating</td>\n",
       "      <td>234 Total Reviews</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>84</th>\n",
       "      <td>Aron Guest House</td>\n",
       "      <td>13.1km from city centre</td>\n",
       "      <td>Rs6713</td>\n",
       "      <td>No Dorm Rooms</td>\n",
       "      <td>Free WiFi</td>\n",
       "      <td>Bed and Breakfast</td>\n",
       "      <td>No Rating</td>\n",
       "      <td>No rating</td>\n",
       "      <td>26 Total Reviews</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>85 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                       Name       Distance from city  \\\n",
       "0                  St Christopher's Village   1.8km from city centre   \n",
       "1                          Generator London     3km from city centre   \n",
       "2   Safestay London Kensington Holland Park   5.9km from city centre   \n",
       "3            PubLove @ The Crown, Battersea   4.7km from city centre   \n",
       "4                               Leman House   3.6km from city centre   \n",
       "..                                      ...                      ...   \n",
       "80                                The Dover   1.9km from city centre   \n",
       "81                         Park Hotel Essex  24.1km from city centre   \n",
       "82                          Cranbrook Hotel  14.8km from city centre   \n",
       "83                               St. Athans   2.9km from city centre   \n",
       "84                         Aron Guest House  13.1km from city centre   \n",
       "\n",
       "       Private_rooms     Dorm_rooms  \\\n",
       "0             Rs3408         Rs1435   \n",
       "1             Rs8571         Rs2169   \n",
       "2             Rs4180         Rs1022   \n",
       "3   No Private Rooms         Rs1239   \n",
       "4             Rs5577  No Dorm Rooms   \n",
       "..               ...            ...   \n",
       "80            Rs6747  No Dorm Rooms   \n",
       "81            Rs3752  No Dorm Rooms   \n",
       "82            Rs3098  No Dorm Rooms   \n",
       "83            Rs3976  No Dorm Rooms   \n",
       "84            Rs6713  No Dorm Rooms   \n",
       "\n",
       "                                             Facility        Description  \\\n",
       "0      Free WiFi,Follows Covid-19 sanitation guidance             Hostel   \n",
       "1      Free WiFi,Follows Covid-19 sanitation guidance             Hostel   \n",
       "2                                           Free WiFi             Hostel   \n",
       "3      Free WiFi,Follows Covid-19 sanitation guidance             Hostel   \n",
       "4                                           Free WiFi             Hostel   \n",
       "..                                                ...                ...   \n",
       "80                           Free WiFi,Free Breakfast              Hotel   \n",
       "81  Free Breakfast,Follows Covid-19 sanitation gui...              Hotel   \n",
       "82  Free Breakfast,Follows Covid-19 sanitation gui...              Hotel   \n",
       "83     Free WiFi,Follows Covid-19 sanitation guidance  Bed and Breakfast   \n",
       "84                                          Free WiFi  Bed and Breakfast   \n",
       "\n",
       "       Rating    Reviews        total reviews  \n",
       "0         8.9   Fabulous  10814 Total Reviews  \n",
       "1         7.5  Very Good   6729 Total Reviews  \n",
       "2         7.9  Very Good   1070 Total Reviews  \n",
       "3         7.9  Very Good    204 Total Reviews  \n",
       "4   No Rating  No rating     13 Total Reviews  \n",
       "..        ...        ...                  ...  \n",
       "80  No Rating  No rating      4 Total Reviews  \n",
       "81  No Rating  No rating    108 Total Reviews  \n",
       "82  No Rating  No rating     58 Total Reviews  \n",
       "83  No Rating  No rating    234 Total Reviews  \n",
       "84  No Rating  No rating     26 Total Reviews  \n",
       "\n",
       "[85 rows x 9 columns]"
      ]
     },
     "execution_count": 445,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Hostels_London=pd.DataFrame({})\n",
    "Hostels_London['Name']=Name\n",
    "Hostels_London['Distance from city']=Distance\n",
    "Hostels_London['Private_rooms']=private_rooms\n",
    "Hostels_London['Dorm_rooms']=dorm_rooms\n",
    "Hostels_London['Facility']=Facility\n",
    "Hostels_London['Description']=description\n",
    "Hostels_London['Rating']=Numer_Rating\n",
    "Hostels_London['Reviews']=overall\n",
    "Hostels_London['total reviews']=Total_Ratings\n",
    "Hostels_London"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
